<!DOCTYPE html>
<head>
  <meta http-equiv="content-type"
 content="text/html; charset=ISO-8859-1">
  <title>BNF Converter Python Mode</title>
</head>
<style>
  table {
    font-family: arial, sans-serif;
    border-collapse: collapse;
    width: 100%;
  }
  
  td, th {
    text-align: left;
    padding: 4px;
  }
  
  </style>
<body>
<div style="text-align: center;">
<h2>BNF Converter</h2>
<h2>Python Mode</h2>
</div> 
<h3>By Bj√∂rn Werner</h3>

<h3>2024</h3>
<p>
  The BNF Converter's Python Backend generates a Python frontend, that uses 
  Antlr4, to parse input into an AST (abstract syntax tree).
</p>
<p>
  BNFC on Github:<br>
  <a href="https://github.com/BNFC/bnfc">https://github.com/BNFC/bnfc</a>
</p>
<p>
  Antlr on Github:<br>
  <a href="https://github.com/antlr/antlr4">https://github.com/antlr/antlr4</a>
</p>
<p>
  Requirements are: the jar file for ANTLRv4, the Python package antlr4, and
  Python 3.10 or higher.
</p>
<h3>Usage</h3>
<div style="margin-left: 40px; "><big><span style="font-family: monospace; ">
    bnfc --python -m NAME.cf</span></big><br style="font-family: monospace; ">
</div>
<p>
There should now exist the following files:
</p>
<table style="padding: 1cm;">
  <tr>
    <th>Filename:</th><th>Description:</th>
  </tr>
  <tr>
    <td>bnfcPyGenNAME/NAMELexer.g4</td><td>Provides the grammar for the lexer.</td>
  </tr>
  <tr>
    <td>bnfcPyGenNAME/NAMEParser.g4</td><td>Provides the grammar for the parser.</td>
  </tr>
  <tr>
    <td>bnfcPyGenNAME/Absyn.py</td><td>Provides the classes for the abstract syntax.</td>
  </tr>
  <tr>
    <td>bnfcPyGenNAME/PrettyPrinter.py</td><td>Provides printing for both the AST and the linearized tree.</td>
  </tr>
  <tr>
    <td>genTest.py</td><td>A ready test-file, that uses the generated frontend to convert input into an AST.</td>
  </tr>
  <tr>
    <td>skele.py</td><td>Provides skeleton code to deconstruct an AST, using structural pattern matching.</td>
  </tr>
</table>
<p>
Make sure the jar for Antlr is accessible from the generated makefile and run the makefile. The generated lexer and parser is placed inside the folder used above.
</p>
<p>
  For example, on linux, export the following variable from .profile:
</p>
<div style="margin-left: 40px; "><big><span style="font-family: monospace; "> 
export ANTLR="$HOME/Downloads/antlr/antlr-4.13.2-complete.jar"</span></big><br style="font-family: monospace; ">
</div>
<p>
  After that it should be possible to run the makefile:
</p>
<div style="margin-left: 40px; "><big><span style="font-family: monospace; ">
    make</span></big><br style="font-family: monospace; ">
</div>
<h3>Testing the frontend</h3>
<p>
  The following example uses a frontend that is generated from a C-like grammar.
</p>
<p style="font-family: monospace;">
  $ python3 genTest.py < hello.c
</p>
<p style="font-family: monospace;">
  Parse Successful!<br>
  <br>
  [Abstract Syntax]<br>
  (PDefs [(DFun Type_int "main" [] [(SExp (EApp "printString" [(EString "Hello world")])), (SReturn (EInt 0))])])<br>
  <br>
  [Linearized Tree]<br>
  int main ()<br>
  {<br>
    &nbsp;printString ("Hello world");<br>
    &nbsp;return 0;<br>
  }<br>
</p>
<h3>The Abstract Syntax Tree</h3>
<p>
  The AST is built up using instances of Python classes, using the dataclass decorator, such as:
</p>
<p style="font-family: monospace;">
@dataclass<br>
class EAdd:<br>
&nbsp;exp_1: Exp<br>
&nbsp;exp_2: Exp<br>
&nbsp;_ann_type: _AnnType = field(default_factory=_AnnType)
</p>
<p>
  The "_ann_type" variable is a placeholder that can be used to store useful information,
  for example type-information in order to create a type-annotated AST.
</p>
<h3>Using the skeleton file</h3>
<p>
  The skeleton file serves as a template, to create an interpreter for example.
  Two different types of matchers are generated: the first with all the value
  categories together, and a second type where each matcher only has one
  individual value category, as in the example below:
</p>
<p style="font-family: monospace;">
def matcherExp(exp_: Exp):<br>
&nbsp;match exp_:<br>
&nbsp;&nbsp;case EAdd(exp_1, exp_2, _ann_type):<br>
&nbsp;&nbsp;&nbsp;# Exp "+" Exp1<br>
&nbsp;&nbsp;&nbsp;raise Exception('EAdd not implemented')<br>
&nbsp;&nbsp;case ESub(exp_1, exp_2, _ann_type):<br>
&nbsp;&nbsp;&nbsp;...
</p>
<p>
  This can be modified, in order to return the addition of each evaluated argument
  category, into:
</p>
<p style="font-family: monospace;">
  def matcherExp(exp_: Exp):<br>
  &nbsp;match exp_:<br>
  &nbsp;&nbsp;case EAdd(exp_1, exp_2, _ann_type):<br>
  &nbsp;&nbsp;&nbsp;# Exp "+" Exp1<br>
  &nbsp;&nbsp;&nbsp;return matcherExp(exp_1) + matcherExp(exp_2)<br>
  &nbsp;&nbsp;case ESub(exp_1, exp_2, _ann_type):<br>
  &nbsp;&nbsp;&nbsp;...
</p>
<p>
  The function can now be imported and used in the generated test file 
  (similarly to how the pretty printer is imported and used):
</p>
<p style="font-family: monospace;">
  from skele import matcherExp<br>
  ...<br>
  print(matcherExp(ast))
</p>
  
<h3>Known issues</h3>
<h4>
  Maximum elements for hand-made list rules:
</h4>
<p>
  If one defines custom rules for lists, such as:
</p>
<p style="font-family: monospace;"> 
 (:) [C] ::= 'a' C 'b' [C] 'c'
</p>
<p>
  the Python backend can not simplify the rule for an iterative approach
  for the parser, meaning at most 1000 elements can be parsed - or a maximum
  recursion depth will be thrown. Using the terminal or separator pragmas should work fine.
</p>
<h4>
  Skeleton code for using lists as entrypoints:
</h4>
<p>
  Matchers for using lists, such as [Exp], are not generated in the
  skeleton code as it may confuse users if the grammar uses several different 
  list categories - as a user may then try to pattern match lists without 
  checking what type the elements have. Users are instead encouraged to use
  non-list entrypoints. 
</p>
<p>
  The improper way to iterate over lists, as the value category is unknown:
</p>
<p style="font-family: monospace;">
  &nbsp;case list():<br>
  &nbsp;&nbsp;for ele in ast:<br>
  &nbsp;&nbsp;&nbsp;...
</p>
<p>
  The proper way to deconstruct lists, where we know the value category:
</p>
<p style="font-family: monospace;">
  &nbsp;case RuleName(listexp_):<br>
  &nbsp;&nbsp;for exp in listexp_:<br>
  &nbsp;&nbsp;&nbsp;...
</p>
<h4>Several entrypoints:</h4>
<p>
  The testfile genTest.py only uses the first entrypoint by default.
</p>
<h4>
  Using multiple separators:
</h4>
<p>
  Using multiple separators for the same category, such as below, generates
  Python functions with overlapping names, causing runtime errors.
</p>
<p style="font-family: monospace;">
  separator Exp1 "," ;<br>
  separator Exp1 ";" ;
</p>
<h4>
Results from the parameterized tests:
</h4>
<p>
  One error among the regression tests are reported: the Java BNFC example grammar contains mutually left recursive rules.
</p>
<h4>
  Example for grammar haskell-hcr:
</h4>
<p>
  Attempting to parse ParCore.hcr from the haskell-hcr example BNFC grammar yields an error for escaped characters.
</p>
