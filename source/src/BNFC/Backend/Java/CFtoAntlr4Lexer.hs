{-
    BNF Converter: Java Antlr4 Lexer generator
    Copyright (C) 2015  Author:  Gabriele Paganelli

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
-}

{-
   **************************************************************
    BNF Converter Module

    Description   : This module generates the Antlr4 input file.
                    Based on CFtoJLex15.hs

    Author        : Gabriele Paganelli (gapag@distruzione.org)

    License       : GPL (GNU General Public License)

    Created       : 15 Oct, 2015

    Modified      :


   **************************************************************
-}

module BNFC.Backend.Java.CFtoAntlr4Lexer ( cf2AntlrLex ) where

import BNFC.CF
import BNFC.Backend.Java.RegToAntlrLexer
import BNFC.Utils (cstring)
import BNFC.Backend.Common.NamedVariables
import Text.PrettyPrint

cf2AntlrLex :: String -> CF -> (Doc, SymEnv)
cf2AntlrLex str cf = cf2jlex str cf

--The environment must be returned for the parser to use.
cf2jlex :: String -> CF -> (Doc, SymEnv)
cf2jlex packageBase cf = (vcat
 [
  prelude packageBase,
  cMacros,
  -- unnamed symbols (those in quotes, not in token definitions)
  lexSymbols env,
  restOfJLex cf
 ], env)
  where
   env = makeSymEnv (cfgSymbols cf ++ reservedWords cf) (0 :: Int)
   makeSymEnv [] _ = []
   makeSymEnv (s:symbs) n = (s, "Surrogate_id_SYMB_" ++ show n) : makeSymEnv symbs (n+1)


-- | File prelude
prelude ::  String -> Doc
prelude packageBase = vcat
    [ "// This Antlr4 file was machine-generated by the BNF converter"
    , "lexer grammar" <+> text packageBase <> "Lexer;"
    ]

--For now all categories are included.
--Optimally only the ones that are used should be generated.
cMacros :: Doc
cMacros = vcat [
    "// Predefined regular expressions in BNFC"
    , "LETTER  : CAPITAL | SMALL;"
    , "CAPITAL : [A-Z\\u00C0-\\u00D6\\u00D8-\\u00DE];"
    , "SMALL   : [a-z\\u00DF-\\u00F6\\u00F8-\\u00FF];"
    , "DIGIT   : [0-9];"
  ]

escapeChars :: String -> String
escapeChars = concatMap escapeChar

-- |
-- This function seems to  take as input a boolean
-- which decides which are the chars to escape (JFlex vs JLex)
-- and the "symbol" name, which is not provided in the .cf grammar,
-- but it is given as a surrogate identifier from the environment
-- The problem here is that the identifier starts with _.
-- This was ok with J(F)Lex implementation because anyway no user-defined identifiers for tokens
-- could start with _
-- Here instead I am forced to make the token begin with a lowercase letter, risking clashes with user-defined tokens.
-- Solution for now: prepend 'surrogate_id_' to all and ignore it.
-- >>> lexSymbols [("foo","bar")]
-- surrogate_id_bar : 'foo';
-- >>> lexSymbols [("\\","bar")]
-- surrogate_id_bar : '\\';
-- >>> lexSymbols [("/","bar")]
-- surrogate_id_bar : '/';
-- >>> lexSymbols [("~","bar")]
-- surrogate_id_bar : '\~';
lexSymbols :: SymEnv -> Doc
lexSymbols ss = vcat $  map transSym ss
  where
    transSym (s,r) =
     text r <>  " : '" <> text (escapeChars s) <> "' ;"


restOfJLex :: CF -> Doc
restOfJLex cf = vcat
    [ lexComments (comments cf)
    , ""
    , userDefTokens
    , ifString strdec
    , ifChar chardec
    , ifC catDouble [
        "// Double predefined token type",
        "DOUBLE : DIGIT+ '.' DIGIT+ ('e' '-'? DIGIT+)?;"
        ]
    , ifC catInteger [
        "//Integer predefined token type",
        "INTEGER : DIGIT+;"
        ]
    , ifC catIdent [
        "// Identifier token type" ,
        "fragment" ,
        "IDENTIFIER_FIRST : LETTER | '_';",
        "IDENT : IDENTIFIER_FIRST (IDENTIFIER_FIRST | DIGIT)*;"
        ]
    ,"// Whitespace"
    ,"WS : (' ' | '\\r' | '\\t' | '\\n')+ ->  skip;"
    , "// Escapable sequences"
    ,"fragment"
    ,"Escapable : ('\"' | '\\\\' | 'n' | 't' | 'r');"
    , ifString stringmodes
    , ifChar charmodes
    ]
  where
    ifC cat s = if isUsedCat cf cat then (vcat s) else ""
    ifString = ifC catString
    ifChar = ifC catChar
    strdec = [
        "// String token type",
        "STRING : '\"' -> more, mode(STRINGMODE);"
        ]
    chardec = ["CHAR : '\\''   -> more, mode(CHARMODE);"]
    userDefTokens = vcat
        [ text (show name) <>" : " <> text (printRegJLex exp) <> ";"
        | (name, exp) <- tokenPragmas cf ]
    stringmodes =
        [ "mode STRESCAPE;",
          "STRESCAPED : Escapable  -> more, popMode ;",
          "mode STRINGMODE;",
          "STRINGESC : '\\\\' -> more , pushMode(STRESCAPE);",
          "STRINGEND : '\"' ->  type(STRING), mode(DEFAULT_MODE);",
          "STRINGTEXT : ~[\\\"\\\\] -> more;"
        ]
    charmodes =
        [
        "mode CHARMODE;",
        "CHARANY     :  ~[\\'\\\\] -> more, mode(CHAREND);",
        "CHARESC     :  '\\\\'  -> more, pushMode(CHAREND),pushMode(ESCAPE);",
        "mode ESCAPE;",
        "ESCAPED : (Escapable | '\\'')  -> more, popMode ;",
        "mode CHAREND;",
        "CHARENDC     :  '\\''  -> type(CHAR), mode(DEFAULT_MODE);"
        ]

lexComments :: ([(String, String)], [String]) -> Doc
lexComments (m,s) =
    vcat (map lexSingleComment s ++ map lexMultiComment m)

-- | Create lexer rule for single-line comments.
--
-- >>> lexSingleComment "--"
-- <YYINITIAL>"--"[^\n]*\n { /* skip */ }
--
-- >>> lexSingleComment "\""
-- <YYINITIAL>"\""[^\n]*\n { /* skip */ }
lexSingleComment :: String -> Doc
lexSingleComment c =
    "COMMENT: '" <> text (escapeChars c) <>  "' ~[\\r\\n]* (('\\r'? '\\n')|EOF) -> skip ;"

-- | Create lexer rule for multi-lines comments.
--
-- There might be a possible bug here if a language includes 2 multi-line
-- comments. They could possibly start a comment with one character and end it
-- with another. However this seems rare.
--
-- >>> lexMultiComment ("{-", "-}")
-- <YYINITIAL>"{-" { yybegin(COMMENT); }
-- <COMMENT>"-}" { yybegin(YYINITIAL); }
-- <COMMENT>. { /* skip */ }
-- <COMMENT>[\n] { /* skip */ }
--
-- >>> lexMultiComment ("\"'", "'\"")
-- <YYINITIAL>"\"'" { yybegin(COMMENT); }
-- <COMMENT>"'\"" { yybegin(YYINITIAL); }
-- <COMMENT>. { /* skip */ }
-- <COMMENT>[\n] { /* skip */ }
lexMultiComment :: (String, String) -> Doc
lexMultiComment (b,e) =
    "MULTICOMMENT : '" <> text (escapeChars b) <>"' (.)*? '"<> text (escapeChars e) <> "' -> skip;"